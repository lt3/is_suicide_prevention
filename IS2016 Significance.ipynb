{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial test\n",
    "\n",
    "A binomial test is a simple and valid way of comparing if a system B performs significantly different (two-tailed) or better (one-tailed) than another system A (e.g. baseline). All that is required are the following variables:\n",
    "* n = number of instances where B prediction differs from A\n",
    "* k = number of instances where B is correct and A is wrong (relative successes)\n",
    "* p = 0.5 (the null hypothesis assumes that system A and B perform equally well: the chance of success of one or the other is a coin flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[p]\n",
      "\\begin{small}\n",
      "\\begin{center}\n",
      "\\begin{tabular}{l|ccccccccc}\n",
      "& \\rotatebox[origin=l]{90}{baseline} & \\rotatebox[origin=l]{90}{FS: none, HO: no} & \\rotatebox[origin=l]{90}{FS: none, HO: yes} & \\rotatebox[origin=l]{90}{FS: group, HO: no} & \\rotatebox[origin=l]{90}{FS: group, HO: yes} & \\rotatebox[origin=l]{90}{FS: nbest, HO: no} & \\rotatebox[origin=l]{90}{FS: nbest, HO: yes} & \\rotatebox[origin=l]{90}{FS: strata, HO: no} & \\rotatebox[origin=l]{90}{FS: strata, HO: yes} \\\\\n",
      "\\hline\n",
      "baseline                       &  -  & *** & *** & *** & *** & *** & *** & *** & *** \\\\\n",
      "FS: none, HO: no               & *** &  -  &     &  *  &  *  &     & *** & *** & *** \\\\\n",
      "FS: none, HO: yes              & *** &     &  -  &     &     &     &     &     & *** \\\\\n",
      "FS: group, HO: no              & *** &  *  &     &  -  &     &     &     &  *  &  *  \\\\\n",
      "FS: group, HO: yes             & *** &  *  &  *  &     &  -  &     &     &     &     \\\\\n",
      "FS: nbest, HO: no              & *** &     &     &     &     &  -  &  *  &  *  &  *  \\\\\n",
      "FS: nbest, HO: yes             & *** &  *  &  *  &     &     &     &  -  &     &     \\\\\n",
      "FS: strata, HO: no             & *** & *** &  *  & *** &     &  *  &     &  -  &     \\\\\n",
      "FS: strata, HO: yes            & *** & *** & *** &  *  &     &  *  &     &     &  -  \\\\\n",
      "\\end{tabular}\n",
      "\\caption{Significance of pairwise difference between system outputs for relevance, $* <= 0.05$, $*** <= 0.0007$ (Bonferroni-adjusted). Above diagonal: F1-optimized systems, below diagonal: F2-optimized systems.}\n",
      "\\label{tab:rel-significance}\n",
      "\\end{center}\n",
      "\\end{small}\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "\n",
    "def clean_name(name):\n",
    "    \"\"\"Reformat name for Table\"\"\"\n",
    "    parts = name.split(\"_\")[2:-1]\n",
    "    if parts[0] == \"baseline\":\n",
    "        return parts[0]\n",
    "    fs, hp = [x.split(\"-\")[1] for x in parts]\n",
    "    return \"FS: %s, HO: %s\" % ({\"n\": \"none\"}.get(fs, fs), {\"n\": \"no\", \"y\": \"yes\"}[hp])\n",
    "\n",
    "def get_pairwise_significance(exp, systems=None):\n",
    "    \"\"\"Binomial test\n",
    "A binomial test is a simple and valid way of comparing if a system B performs significantly different (two-tailed) or better (one-tailed) than another system A (e.g. baseline). All that is required are the following variables:\n",
    "n = number of instances where B prediction differs from A\n",
    "k = number of instances where B is correct and A is wrong (relative successes)\n",
    "p = 0.5 (the null hypothesis assumes that system A and B perform equally well: the chance of success of one or the other is a coin flip)\"\"\"\n",
    "    fp = \"data/results_%s_and_baseline.csv\" % exp\n",
    "    df = pandas.read_csv(fp) # Gold standard is always in the _0 column, predictions in the _1 column\n",
    "    gold = list(df[\"_svm_baseline_0\"])\n",
    "    \n",
    "    res = []\n",
    "    for compare_to in systems:\n",
    "        base = list(df[compare_to])\n",
    "     \n",
    "        sig = [clean_name(compare_to).replace(\"_\", \"\\_\").ljust(30)]\n",
    "        for col in systems:\n",
    "            pred = list(df[col])\n",
    "    \n",
    "            # Binomial\n",
    "            n = sum(1 for i in range(len(base)) if base[i] != pred[i]) # Number of trials\n",
    "            k = sum(1 for i in range(len(base)) if (base[i] != pred[i]) and (pred[i] == gold[i])) # Number of successes\n",
    "            p = scipy.stats.binom_test(k, n=n, p=0.5, alternative='two-sided')\n",
    "            if col == compare_to:\n",
    "                sig.append(\" - \")\n",
    "            elif p < 0.0014:\n",
    "                sig.append(\"***\")\n",
    "            elif p < 0.05:\n",
    "                sig.append(\" * \")\n",
    "            else:\n",
    "                sig.append(\"   \")\n",
    "        res.append(sig)\n",
    "    return res\n",
    "\n",
    "def zip_results(res1, res2):\n",
    "    \"\"\"Combine two sets of results into an upper right (res1) and lower left (res2) half of a table\"\"\"\n",
    "    res_zipped = []\n",
    "    for i, pair in enumerate(zip(res1, res2)):\n",
    "        res_zipped.append(pair[1][:i+1] + pair[0][i+1:])\n",
    "    return res_zipped\n",
    "\n",
    "def latex_rotate(s):\n",
    "    \"\"\"Format s as a vertical string\"\"\"\n",
    "    return \"\\\\rotatebox[origin=l]{90}{%s}\" % s.replace(\"_\", \"\\_\")\n",
    "\n",
    "def print_latex_table(exp, res):\n",
    "    \"\"\"Format results as a LaTeX source code for a table\"\"\"\n",
    "    rotated = [latex_rotate(clean_name(s)) for s in systems]\n",
    "    print \"\\\\begin{table*}[p]\\n\\\\begin{small}\\n\\\\begin{center}\\n\\\\begin{tabular}{l|ccccccccc}\"\n",
    "    print \"& \" + \" & \".join(rotated) + \" \\\\\\\\\"\n",
    "    print \"\\\\hline\"\n",
    "    for sig in res: \n",
    "        print \" & \".join(sig) + \" \\\\\\\\\"\n",
    "    print \"\\\\end{tabular}\"\n",
    "    print \"\\\\caption{Significance of pairwise difference between system outputs for %s, $* <= 0.05$, $*** <= 0.0007$ (Bonferroni-adjusted). Above diagonal: F1-optimized systems, below diagonal: F2-optimized systems.}\" % exp\n",
    "    print \"\\\\label{tab:%s-significance}\" % exp[:3]\n",
    "    print \"\\\\end{center}\\n\\\\end{small}\\n\\\\end{table*}\"\n",
    "\n",
    "def exp_to_latex(exp, systems):\n",
    "    \"\"\"Given an experiment (relevance/severity), produce a LaTeX table with F1 and F2 optimized significances.\"\"\"\n",
    "    res1 = get_pairwise_significance(exp, systems=systems)\n",
    "    res2 = get_pairwise_significance(exp + \"_f2\", systems=systems)\n",
    "    res_zipped = zip_results(res1, res2)\n",
    "    print_latex_table(exp, res_zipped)\n",
    "\n",
    "exp = \"relevance\"\n",
    "systems = ['_svm_baseline_1', '_svm_fs-n_hp-n_1', '_svm_fs-n_hp-y_1', '_svm_fs-group_hp-n_1', '_svm_fs-group_hp-y_1', '_svm_fs-nbest_hp-n_1', '_svm_fs-nbest_hp-y_1', '_svm_fs-strata_hp-n_1', '_svm_fs-strata_hp-y_1']\n",
    "exp_to_latex(exp, systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial test on systems from different optimization objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 , NOT SIGNIFICANT\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import scipy\n",
    "from collections import Counter\n",
    "\n",
    "def clean_name(name):\n",
    "    return \"_\".join(name.split(\"_\")[2:-1])\n",
    "\n",
    "exp1 = \"relevance\"\n",
    "fp1 = \"data/results_%s_and_baseline.csv\" % exp1\n",
    "df1 = pandas.read_csv(fp1) # Gold standard is always in the _0 column, predictions in the _1 column\n",
    "exp2 = \"relevance_f2\"\n",
    "fp2 = \"data/results_%s_and_baseline.csv\" % exp2\n",
    "df2 = pandas.read_csv(fp2) # Gold standard is always in the _0 column, predictions in the _1 column\n",
    "\n",
    "assert fp1 != fp2\n",
    "\n",
    "system1 = '_svm_fs-strata_hp-y_1'\n",
    "system2 = '_svm_fs-strata_hp-y_1'\n",
    "gold = list(df1[\"_svm_baseline_0\"])\n",
    "pred1 = list(df1[system1])\n",
    "pred2 = list(df2[system2])\n",
    "\n",
    "# Binomial\n",
    "n = sum(1 for i in range(len(pred1)) if pred1[i] != pred2[i]) # Number of trials\n",
    "k = sum(1 for i in range(len(pred1)) if (pred1[i] != pred2[i]) and (pred1[i] == gold[i])) # Number of successes\n",
    "p = scipy.stats.binom_test(k, n=n, p=0.5, alternative='two-sided')\n",
    "assert pred1 != pred2 # Highly unlikely to be identical, but it is possible\n",
    "if p <= 0.001:\n",
    "    print p, \", SIGNIFICANT ***\"\n",
    "elif p <= 0.01:\n",
    "    print p, \", SIGNIFICANT **\"\n",
    "elif p <= 0.05:\n",
    "    print p, \", SIGNIFICANT *\"\n",
    "else:\n",
    "    print p, \", NOT SIGNIFICANT\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
